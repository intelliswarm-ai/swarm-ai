services:
  ollama:
    image: ollama/ollama:latest
    container_name: stock-analysis-ollama
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_NOPRUNE=1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s  # Reduced frequency to minimize log noise
      timeout: 5s
      start_period: 30s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Ollama image entrypoint is already "ollama serve"
    # Model will be pulled by the app on first use

  # Separate service to pull the model after Ollama starts
  ollama-pull:
    image: ollama/ollama:latest
    container_name: stock-analysis-ollama-pull
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["ollama", "pull", "mistral:7b"]
    restart: "no"

  stock-analysis:
    build:
      context: ../..
      dockerfile: examples/stock/Dockerfile
    container_name: stock-analysis-app
    depends_on:
      ollama:
        condition: service_healthy
      ollama-pull:
        condition: service_completed_successfully
    environment:
      - SPRING_PROFILES_ACTIVE=local
      - SPRING_AI_OLLAMA_BASE_URL=http://ollama:11434
      - SPRING_AI_OLLAMA_CHAT_OPTIONS_MODEL=mistral:7b
      - STOCK_TICKER=AAPL
    volumes:
      - ./config:/app/config
      - ./output:/app/output
    restart: unless-stopped

volumes:
  ollama_data: